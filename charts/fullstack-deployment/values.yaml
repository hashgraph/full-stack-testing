global:
  namespaceOverride: ""
  ingressClassName: "hedera-explorer-ingress-class" # override for multiple deployments within the same cluster and make unique per cluster

# cloud configuration
cloud:
  buckets:
    streamBucket: "fst-streams"
    backupBucket: "fst-backups"
  minio:
    enabled: true
  acmeClusterIssuer:
    enabled: false
  selfSignedClusterIssuer:
    enabled: false
  haproxyIngressController:
    enabled: false

# telemetry configurations
telemetry:
  prometheus:
    svcMonitor:
      enabled: true

# reduce default termination grace period
terminationGracePeriodSeconds: 10

# helm test container
tester:
  deployPodMonitor: true
  clusterRoleName: "pod-monitor-role" # this is a shared cluster role for all namespaces
  image:
    registry: "ghcr.io"
    repository: "hashgraph/full-stack-testing/kubectl-bats"
    tag: "" # this should be empty since we want the default behavior of $.Chart.appVersion to apply
    pullPolicy: "IfNotPresent"
  resources: {}

# lets encrypt acme cluster issuer configuration
acme-cluster-issuer:
  issuers:
    staging:
      email: ""
      name: '{{ .Values.global.namespaceOverride | default .Release.Namespace | printf "%s-letsencrypt-staging" }}'
    production:
      email: ""
      name: '{{ .Values.global.namespaceOverride | default .Release.Namespace | printf "%s-letsencrypt-prod" }}'
  solvers: # TODO change in: https://github.com/hashgraph/full-stack-testing/issues/631
    http01:
      solverType: "ingress"

# default settings for a single node
# This default configurations can be overridden for each node in the hedera.nodes section.
defaults:
  volumeClaims:
    enabled: false
    node:
      accountBalances: "100Gi"
      eventStreams: "100Gi"
      recordStreams: "100Gi"
      dataOnboard: "1Gi"
      dataSaved: "500Gi"
      dataStats: "50Gi"
      dataUpgrade: "5Gi"
      output: "5Gi"
  root: # root container
    image:
      registry: "ghcr.io"
      repository: "hashgraph/full-stack-testing/ubi8-init-java17"
      tag: "" # this should be empty since we want the default behavior of $.Chart.appVersion to apply
      pullPolicy: "IfNotPresent"
    resources:
      requests:
        cpu: 100m
        memory: 100Mi
      limits:
        cpu: 1
        memory: 2G
  haproxy:
    enabled: true
    nameOverride: "haproxy"
    image:
      registry: "docker.io"
      repository: "haproxytech/haproxy-alpine"
      tag: "2.4.25"
      pullPolicy: "IfNotPresent"
    resources: {}
    serviceType: "LoadBalancer"
  envoyProxy:
    enabled: true
    nameOverride: "envoy-proxy"
    image:
      registry: "docker.io"
      repository: "envoyproxy/envoy"
      tag: "v1.21.1"
      pullPolicy: "IfNotPresent"
    resources: {}
    loadBalancerEnabled: false
  sidecars:
    recordStreamUploader:
      enabled: true
      nameOverride: "record-stream-uploader"
      image:
        registry: "gcr.io"
        repository: "hedera-registry/uploader-mirror"
        tag: "1.3.0"
        pullPolicy: "IfNotPresent"
      config:
        debug: true
        compression: true
        sidecar: true
        reaper:
          enabled: true
          minKeep: 1
          interval: 1
          defaultBackoff: 1
        signature:
          require: true
          prioritize: true
      resources: {}
    eventStreamUploader:
      enabled: true
      nameOverride: "event-stream-uploader"
      image:
        registry: "gcr.io"
        repository: "hedera-registry/uploader-mirror"
        tag: "1.3.0"
        pullPolicy: "IfNotPresent"
      config:
        debug: true
        compression: true
        reaper:
          enabled: true
          minKeep: 1
          interval: 1
          defaultBackoff: 1
        signature:
          require: true
          prioritize: true
      resources: {}
    accountBalanceUploader:
      enabled: true
      nameOverride: "account-balance-uploader"
      image:
        registry: gcr.io
        repository: hedera-registry/uploader-mirror
        tag: "1.3.0"  # Defaults to the chart's app version if empty
        pullPolicy: "IfNotPresent"
      config:
        debug: true
        compression: true
        reaper:
          enabled: true
          minKeep: 1
          interval: 1
          defaultBackoff: 1
        signature:
          require: true
          prioritize: true
      resources: {}
    backupUploader:
      enabled: false
      nameOverride: "backup-uploader"
      image:
        registry: "gcr.io"
        repository: "hedera-registry/hedera-backups"
        tag: "0.6.0"
        pullPolicy: "IfNotPresent"
      config:
        backupBucket: "backup"
      resources: {}
    otelCollector:
      enabled: true
      nameOverride: ""
      image:
        registry: "docker.io"
        repository: "otel/opentelemetry-collector-contrib"
        tag: "0.72.0"
        pullPolicy: "IfNotPresent"
      resources: {}
      receivers:
        prometheus:
          scrapeTargets: [ 0.0.0.0:9999 ]  # hedera node metrics are exposed at port 9999
          scrapeInterval: 5s
      exporters:
        otlp:
          endpoint: tempo:4317
          tls:
            insecure: true
        prometheus:
          tls:
            insecure: true
        prometheusRemoteWrite:
          enabled: false
          endpoint: "" # e.g. http://prometheus.<NAMESPACE>.svc:9090/api/v1/write
          tls:
            insecure: true

# This configures the minio tenant subchart
# Reference for configuration: https://github.com/minio/operator/blob/master/helm/tenant/values.yaml
minio-server:
  secrets:
    # This secret has [accessKey, secretKey] and will be randomly generated by helm
    existingSecret: minio-secrets
  tenant:
    buckets:
      - name: fst-streams
      - name: fst-backups
    name: minio
    pools:
      - servers: 1
        name: pool-1
        volumesPerServer: 1
        size: 10Gi
        nodeSelector: {}
        labels:
          fullstack.hedera.com/testSuiteName: ""
          fullstack.hedera.com/testName: ""
          fullstack.hedera.com/testRunUID: ""
          fullstack.hedera.com/testCreationTimestamp: ""
          fullstack.hedera.com/testExpirationTimestamp: ""
          fullstack.hedera.com/testRequester: ""
        tolerations:
          - key: "fullstack-scheduling.io/os"
            operator: "Equal"
            value: "linux"
            effect: "NoSchedule"
          - key: "fullstack-scheduling.io/role"
            operator: "Equal"
            value: "network"
            effect: "NoSchedule"
    configuration:
      name: minio-secrets
    certificate:
      requestAutoCert: false
  environment:
    MINIO_BROWSER_LOGIN_ANIMATION: off # https://github.com/minio/console/issues/2539#issuecomment-1619211962

# hedera mirror node configuration
hedera-mirror-node:
  enabled: false # set to false during first deployment, then do an upgrade with it enabled and supply the base64 encoded addressbook
  labels:
    fullstack.hedera.com/testSuiteName: ""
    fullstack.hedera.com/testName: ""
    fullstack.hedera.com/testRunUID: ""
    fullstack.hedera.com/testCreationTimestamp: ""
    fullstack.hedera.com/testExpirationTimestamp: ""
    fullstack.hedera.com/testRequester: ""
  graphql: # not needed for default FST use case
    enabled: false
  rosetta: # not needed for default FST use case
    enabled: false
  redis:
    enabled: false # not needed for default FST use case
  web3:
    enabled: false
  global:
    namespaceOverride: "{{ tpl (.Values.global.namespaceOverride | toString) }}"

  # importer is a component of the hedera mirror node
  # config for subchart hedera-mirror/importer
  importer:
    nodeSelector: {}
    tolerations:
      - key: "fullstack-scheduling.io/os"
        operator: "Equal"
        value: "linux"
        effect: "NoSchedule"
      - key: "fullstack-scheduling.io/role"
        operator: "Equal"
        value: "network"
        effect: "NoSchedule"
    envFrom:
      - secretRef:
          name: mirror-passwords
      - secretRef:
          name: "{{ .Release.Name }}-redis"
      - secretRef:
          name: uploader-mirror-secrets
    # The addressbook.bin file updates will be handled by infrastructure code or solo
    addressBook: ""
    config:
      # importer is a springboot app, its application.yaml configuration starts here
      # This config is mounted at [/usr/etc/hedera/application.yaml] in the importer pod
      hedera:
        mirror:
          importer:
            network: other
            downloader:
              allowAnonymousAccess: false
              bucketName: "fst-streams"
              # for s3 configuration of mirror node look at uploader-mirror-secrets.yaml
            parser:
              record:
                entity:
                  notify:
                    enabled: true
                  redis:
                    enabled: false
      management:
        endpoint:
          health:
            group:
              readiness:
                exclude: redis
  grpc:
    nodeSelector: {}
    tolerations:
      - key: "fullstack-scheduling.io/os"
        operator: "Equal"
        value: "linux"
        effect: "NoSchedule"
      - key: "fullstack-scheduling.io/role"
        operator: "Equal"
        value: "network"
        effect: "NoSchedule"
    config:
      hedera:
        mirror:
          grpc:
            listener:
              type: NOTIFY
      management:
        endpoint:
          health:
            group:
              readiness:
                exclude: redis
  postgresql:
    postgresql:
      nodeSelector: {}
      tolerations:
        - key: "fullstack-scheduling.io/os"
          operator: "Equal"
          value: "linux"
          effect: "NoSchedule"
        - key: "fullstack-scheduling.io/role"
          operator: "Equal"
          value: "network"
          effect: "NoSchedule"
    pgpool:
      replicaCount: 0
  rest:
    nodeSelector: {}
    tolerations:
      - key: "fullstack-scheduling.io/os"
        operator: "Equal"
        value: "linux"
        effect: "NoSchedule"
      - key: "fullstack-scheduling.io/role"
        operator: "Equal"
        value: "network"
        effect: "NoSchedule"
    monitor:
      enabled: false

haproxy-ingress:
  controller:
    service:
      loadBalancerIP: "" # the external IP address of the hedera mirror node explorer

# hedera-mirror-node-explorer configuration
hedera-explorer:
  enabled: false # set to false during first deployment, then do an upgrade with it enabled and supply the base64 encoded addressbook
  # leave blank to use default, set if you have multiple deployments in a cluster to make it unique
  selfSignedCertClusterIssuer: '{{ .Values.global.namespaceOverride | default .Release.Namespace | printf "%s-self-signed-cluster-issuer" }}'
  certClusterIssuerType: "self-signed" # "acme-staging", "acme-prod", or "self-signed"
  ingress:
    enabled: false
    hosts:
      - host: "explorer.fst.local"
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: ca-secret-hedera-explorer
        hosts:
          - '{{ index .Values.ingress.hosts 0 "host" }}'
  labels:
    fullstack.hedera.com/testSuiteName: ""
    fullstack.hedera.com/testName: ""
    fullstack.hedera.com/testRunUID: ""
    fullstack.hedera.com/testCreationTimestamp: ""
    fullstack.hedera.com/testExpirationTimestamp: ""
    fullstack.hedera.com/testRequester: ""
  nodeSelector: {}
  tolerations:
    - key: "fullstack-scheduling.io/os"
      operator: "Equal"
      value: "linux"
      effect: "NoSchedule"
    - key: "fullstack-scheduling.io/role"
      operator: "Equal"
      value: "network"
      effect: "NoSchedule"
  global:
    namespaceOverride: "{{ .Values.global.namespaceOverride }}"
  # The hedera explorer UI /api url will proxy  all request to mirror node
  #
  # Without this we would need to expose the mirror node rest API publicly and specify its public url in the network config below
  proxyPass:
    /api: "http://{{ .Release.Name }}-rest"

  # In the json config below we are using the url as "/", instead of a regular http://mainnet.url
  # This makes the explorer UI make a relative request to its own url
  # This in combination with proxyPass above saves us the need to expose mirror node URL publicly
  config: |
    [
      {
        "name": "localnet",
        "displayName": "LOCALNET",
        "url": "/",
        "ledgerID": "03"
      }
    ]

# common deployment configuration
deployment:
  podAnnotations: {}
  podLabels: {}
  nodeSelector: {}
  tolerations:
    - key: "fullstack-scheduling.io/os"
      operator: "Equal"
      value: "linux"
      effect: "NoSchedule"
    - key: "fullstack-scheduling.io/role"
      operator: "Equal"
      value: "network"
      effect: "NoSchedule"
  # Specify pod affinity
  # Use complete affinity spec starting with key "nodeAffinity:"
  # Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity
  affinity: {}
  priorityClassName: {}
  ## PodDisruptionBudget for fullstack testing pods
  ## Default backend Pod Disruption Budget configuration
  ## ref: https://kubernetes.io/docs/tasks/run-application/configure-pdb/
  ## @param deployment.podDisruptionBudget.create Enable Pod Disruption Budget configuration
  ## @param deployment.podDisruptionBudget.minAvailable Minimum number/percentage of pods that should remain scheduled
  ## @param deployment.podDisruptionBudget.maxUnavailable Maximum number/percentage of pods that should remain scheduled
  ##
  podDisruptionBudget:
    create: true
    minAvailable: 1
    maxUnavailable: ""
  testMetadata:
    enabled: false
    testSuiteName: ""
    testName: ""
    testRunUID: ""
    testCreationTimestamp: ""
    testExpirationTimestamp: ""
    testRequester: ""

# hedera node configuration
# Only the name of the node is required. The rest of the configuration will be inherited from `defaults` section
hedera:
  nodes:
    - name: node0
      accountId: 0.0.3
    - name: node1
      accountId: 0.0.4
    - name: node2
      accountId: 0.0.5
